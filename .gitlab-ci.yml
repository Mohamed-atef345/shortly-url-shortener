workflow:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: "$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH"

variables:
  COMMIT_SHA: $CI_COMMIT_SHORT_SHA
  CACHE_KEY: $CI_COMMIT_REF_SLUG

  ACR_NAME: "shortlyacr"
  ACR_URL: "shortlyacr.azurecr.io"
  RESOURCE_GROUP: "shortly-prod"
  CLUSTER_NAME: "shortly-aks"
  DOMAIN: "myshortly.tech"

stages:
  - test
  - infra
  - build
  - scan
  - deploy

test_frontend:
  image: oven/bun:alpine
  stage: test
  cache:
    key: $CACHE_KEY
    paths:
      - frontend/node_modules
  script:
    - cd frontend
    - bun install
    - bun run lint
    - bun run typecheck

test_backend:
  image: oven/bun:alpine
  stage: test
  cache:
    key: $CACHE_KEY
    paths:
      - backend/node_modules
  script:
    - cd backend
    - bun install
    - bun test
    - bun run lint
    - bun run typecheck

infra_plan:
  image:
    name: hashicorp/terraform:latest
    entrypoint: [""]
  stage: infra
  before_script:
    - cd DevOps/terraform
    - terraform init -backend-config="access_key=$TF_STATE_ACCESS_KEY"
  script:
    - terraform plan -out=tfplan
  artifacts:
    paths:
      - DevOps/terraform/tfplan
    expire_in: 1 hour

infra_apply:
  image:
    name: hashicorp/terraform:latest
    entrypoint: [""]
  stage: infra
  needs: [infra_plan]
  before_script:
    - cd DevOps/terraform
    - terraform init -backend-config="access_key=$TF_STATE_ACCESS_KEY"
  script:
    - terraform apply -auto-approve tfplan
    - echo "ACR_URL=$(terraform output -raw shortlyacr_url)" >> ../deploy.env
    - echo "RESOURCE_GROUP=$(terraform output -raw resource_group_name)" >> ../deploy.env
    - echo "CLUSTER_NAME=$(terraform output -raw kubernetes_cluster_name)" >> ../deploy.env
    - echo "INGRESS_STATIC_IP=$(terraform output -raw ingress_ip)" >> ../deploy.env
  artifacts:
    reports:
      dotenv: DevOps/deploy.env

build_and_push_backend:
  image: docker:latest
  stage: build
  services:
    - docker:dind
  variables:
    DOCKER_TLS_CERTDIR: ""
  before_script:
    # Login to ACR using service principal credentials
    - docker login $ACR_URL -u $ARM_CLIENT_ID -p $ARM_CLIENT_SECRET
  script:
    # Build image
    - docker build -t $ACR_URL/shortly-backend:$COMMIT_SHA -t $ACR_URL/shortly-backend:latest ./backend
    # Push both tags (commit SHA for rollback + latest for convenience)
    - docker push $ACR_URL/shortly-backend:$COMMIT_SHA
    - docker push $ACR_URL/shortly-backend:latest
  after_script:
    - docker logout $ACR_URL

push_redis_to_acr:
  image: docker:latest
  stage: build
  services:
    - docker:dind
  variables:
    DOCKER_TLS_CERTDIR: ""
  rules:
    - if: "$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH"
      allow_failure: true
  before_script:
    - docker login $ACR_URL -u $ARM_CLIENT_ID -p $ARM_CLIENT_SECRET
  script:
    #Authenticate to dhi to download hardened image
    - docker login dhi.io -u $DHI_USERNAME -p $DHI_PASSWORD
    # Pull official Redis image and re-tag for ACR
    - docker pull dhi.io/redis:8-debian13-dev
    - docker tag dhi.io/redis:8-debian13-dev $ACR_URL/redis:8-debian13-dev
    - docker push $ACR_URL/redis:8-debian13-dev
    #Logout from dhi
    - docker logout dhi.io
  after_script:
    - docker logout $ACR_URL

build_and_push_frontend:
  image: docker:latest
  stage: build
  services:
    - docker:dind
  variables:
    DOCKER_TLS_CERTDIR: ""
  before_script:
    - docker login $ACR_URL -u $ARM_CLIENT_ID -p $ARM_CLIENT_SECRET
  script:
    # Build with NEXT_PUBLIC_* baked in at build time
    - >
      docker build
      --build-arg NEXT_PUBLIC_API_URL=https://$DOMAIN
      --build-arg NEXT_PUBLIC_BASE_URL=https://$DOMAIN
      -t $ACR_URL/shortly-frontend:$COMMIT_SHA
      -t $ACR_URL/shortly-frontend:latest
      ./frontend
    - docker push $ACR_URL/shortly-frontend:$COMMIT_SHA
    - docker push $ACR_URL/shortly-frontend:latest
  after_script:
    - docker logout $ACR_URL

scan_backend:
  image:
    name: ghcr.io/aquasecurity/trivy:latest
    entrypoint: [""]
  stage: scan
  variables:
    TRIVY_USERNAME: $ARM_CLIENT_ID
    TRIVY_PASSWORD: $ARM_CLIENT_SECRET
  script:
    # Fail pipeline on CRITICAL vulnerabilities
    - trivy image
      --exit-code 1
      --severity CRITICAL
      --ignore-unfixed
      --format table
      $ACR_URL/shortly-backend:$COMMIT_SHA
    # Generate full report (all severities) as artifact
    - trivy image
      --format json
      --output backend-trivy-report.json
      $ACR_URL/shortly-backend:$COMMIT_SHA
  artifacts:
    paths:
      - backend-trivy-report.json
    expire_in: 1 week

scan_frontend:
  image:
    name: ghcr.io/aquasecurity/trivy:latest
    entrypoint: [""]
  stage: scan
  variables:
    TRIVY_USERNAME: $ARM_CLIENT_ID
    TRIVY_PASSWORD: $ARM_CLIENT_SECRET
  script:
    # Fail pipeline on CRITICAL vulnerabilities
    - trivy image
      --exit-code 1
      --severity CRITICAL
      --ignore-unfixed
      --format table
      $ACR_URL/shortly-frontend:$COMMIT_SHA
    # Generate full report (all severities) as artifact
    - trivy image
      --format json
      --output frontend-trivy-report.json
      $ACR_URL/shortly-frontend:$COMMIT_SHA
  artifacts:
    paths:
      - frontend-trivy-report.json
    expire_in: 1 week

deploy_to_aks:
  image: mcr.microsoft.com/azure-cli:latest
  stage: deploy
  rules:
    - if: "$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH"
  before_script:
    - tdnf install -y tar git gawk wget sudo
    # Install kubectl — try dynamic version, fall back to pinned version
    - KUBECTL_FALLBACK_VERSION="v1.35.0"
    - K8S_VERSION="$(curl -fsSL --max-time 5 https://dl.k8s.io/release/stable.txt || true)"
    - if [ -z "$K8S_VERSION" ]; then echo "Upstream version endpoint unavailable, using fallback $KUBECTL_FALLBACK_VERSION"; K8S_VERSION="$KUBECTL_FALLBACK_VERSION"; fi
    - echo "Installing kubectl $K8S_VERSION"
    - curl -fL --retry 3 -o kubectl "https://dl.k8s.io/release/${K8S_VERSION}/bin/linux/amd64/kubectl"
    - sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
    - kubectl version --client
    - curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
    # Login to Azure and get AKS credentials
    - az login --service-principal -u $ARM_CLIENT_ID -p $ARM_CLIENT_SECRET --tenant $ARM_TENANT_ID
    - az aks get-credentials --resource-group $RESOURCE_GROUP --name $CLUSTER_NAME --overwrite-existing
  script:
    # Install NGINX Ingress Controller
    - |
      helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
      helm repo update
      helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
        --create-namespace \
        --namespace ingress-nginx \
        -f ./DevOps/k8s/nginx-ingress-values.yaml \
        --set controller.service.loadBalancerIP=$INGRESS_STATIC_IP \
        --set controller.service.annotations."service\.beta\.kubernetes\.io/azure-load-balancer-resource-group"=$RESOURCE_GROUP
    # Install cert-manager for TLS certificate management
    - |
      curl -LO https://cert-manager.io/public-keys/cert-manager-keyring-2021-09-20-1020CF3C033D4F35BAE1C19E1226061C665DF13E.gpg
      helm upgrade --install \
      cert-manager oci://quay.io/jetstack/charts/cert-manager \
      --version v1.19.2 \
      --namespace cert-manager \
      --create-namespace \
      --verify \
      --keyring ./cert-manager-keyring-2021-09-20-1020CF3C033D4F35BAE1C19E1226061C665DF13E.gpg \
      --set crds.enabled=true
    # Install Sealed Secrets Controller (apply sealing key before first install)
    - |
      if ! helm list -n kube-system | grep -q sealed-secrets; then
        kubectl apply -f $SEALED_SECRETS_KEY
        helm repo add sealed-secrets https://bitnami-labs.github.io/sealed-secrets
        helm repo update
        helm install sealed-secrets sealed-secrets/sealed-secrets \
          --namespace kube-system \
          --set-string fullnameOverride=sealed-secrets-controller
      fi
    # Install Prometheus and Grafana
    - |
      helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
      helm repo update
      helm upgrade --install monitoring prometheus-community/kube-prometheus-stack \
        --namespace monitoring \
        --create-namespace \
        -f ./DevOps/k8s/prometheus-stack-values.yaml \
        --set grafana.adminPassword=$GRAFANA_ADMIN_PASSWORD
    # Deploy the application with Helm
    - >
      helm upgrade --install shortly ./DevOps/k8s/shorly
      --set backend.image=$ACR_URL/shortly-backend
      --set backend.tag=$COMMIT_SHA
      --set frontend.image=$ACR_URL/shortly-frontend
      --set frontend.tag=$COMMIT_SHA
      --set redis.image=$ACR_URL/redis
      --set redis.tag=8-debian13-dev
      --set clusterIssuer.acmeEmail=$ACMEEMAIL
    # Verify deployment
    - kubectl rollout status deployment/shortly-backend-deployment --timeout=120s
    - kubectl rollout status deployment/shortly-frontend-deployment --timeout=120s
    # Show summary
    - kubectl get pods
    - kubectl get svc
    - kubectl get ingress
    # Show the static IP for DNS configuration
    - |
      echo "============================================"
      echo "  STATIC IP: $INGRESS_STATIC_IP"
      echo "  Point The DNS A record for $DOMAIN → $INGRESS_STATIC_IP"
      echo "============================================"
